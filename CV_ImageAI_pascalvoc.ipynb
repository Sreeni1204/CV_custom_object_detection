{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageAI_CV.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ece30a54-7bf1-45a5-b6a4-510f3c2c5975","executionInfo":{"status":"ok","timestamp":1575662683578,"user_tz":-60,"elapsed":24828,"user":{"displayName":"sreeni vasa hv","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGRGILT9ymLBiio6LAzf9v1Yur0IFEmPAOx9tG-0I=s64","userId":"10395202719377635148"}},"id":"aQJvfAy50XLM","colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q9lAfYCc0Zeg","colab_type":"code","outputId":"3a82b9fb-974b-4982-d8c8-d9f720a8b4ab","executionInfo":{"status":"ok","timestamp":1575728222354,"user_tz":-60,"elapsed":6066,"user":{"displayName":"sreeni vasa hv","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGRGILT9ymLBiio6LAzf9v1Yur0IFEmPAOx9tG-0I=s64","userId":"10395202719377635148"}},"colab":{"base_uri":"https://localhost:8080/","height":332}},"source":["!pip3 install imageai"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting imageai\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n","\r\u001b[K     |█▉                              | 10kB 29.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.1.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (4.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.17.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.8.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.3.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.6.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.5)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageai) (0.46)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imageai) (42.0.1)\n","Installing collected packages: imageai\n","Successfully installed imageai-2.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YjdJPrvE0h3n","colab_type":"code","outputId":"26b228f7-86c5-459a-8738-6b76c0199282","executionInfo":{"status":"ok","timestamp":1575728268832,"user_tz":-60,"elapsed":40086,"user":{"displayName":"sreeni vasa hv","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGRGILT9ymLBiio6LAzf9v1Yur0IFEmPAOx9tG-0I=s64","userId":"10395202719377635148"}},"colab":{"base_uri":"https://localhost:8080/","height":662}},"source":["!pip3 install tensorflow-gpu==1.13.1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n","\u001b[K     |████████████████████████████████| 345.2MB 45kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 38.3MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.6)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 71.4MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.17.4)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.16.0)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (42.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-1XCPDbZ0wub","colab_type":"code","colab":{}},"source":["from imageai.Detection.Custom import DetectionModelTrainer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0m7wMhdf00QV","colab_type":"code","colab":{}},"source":["dataset = \"/content/Pascal_voc\"\n","pretrained_model = \"/content/pretrained/detection_model-ex-012--loss-0009.033.h5\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaaURPsd2lcE","colab_type":"code","outputId":"f24f53bf-2810-410a-8ab0-a851782b0490","executionInfo":{"status":"ok","timestamp":1575734062933,"user_tz":-60,"elapsed":5741752,"user":{"displayName":"sreeni vasa hv","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGRGILT9ymLBiio6LAzf9v1Yur0IFEmPAOx9tG-0I=s64","userId":"10395202719377635148"}},"colab":{"base_uri":"https://localhost:8080/","height":714}},"source":["trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=dataset)\n","trainer.setTrainConfig(object_names_array=[\"Peanut\", \"Walnut\", \"Haselnut\"], batch_size=4, num_experiments=10, train_from_pretrained_model=pretrained_model)\n","trainer.trainModel()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n","Average IOU for 9 anchors: 0.83\n","Anchor Boxes generated.\n","Detection configuration saved in  /content/Pascal_voc/json/detection_config.json\n","Training on: \t['Haselnut', 'Peanut', 'Walnut']\n","Training with Batch Size:  4\n","Number of Experiments:  10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Training with transfer learning from pretrained Model\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/10\n","600/600 [==============================] - 605s 1s/step - loss: 10.6292 - yolo_layer_1_loss: 3.3746 - yolo_layer_2_loss: 2.2441 - yolo_layer_3_loss: 5.0105 - val_loss: 11.2130 - val_yolo_layer_1_loss: 3.1426 - val_yolo_layer_2_loss: 2.2789 - val_yolo_layer_3_loss: 5.7915\n","Epoch 2/10\n","600/600 [==============================] - 565s 941ms/step - loss: 9.0195 - yolo_layer_1_loss: 2.4602 - yolo_layer_2_loss: 2.0920 - yolo_layer_3_loss: 4.4673 - val_loss: 11.3629 - val_yolo_layer_1_loss: 3.0241 - val_yolo_layer_2_loss: 2.5563 - val_yolo_layer_3_loss: 5.7826\n","Epoch 3/10\n","600/600 [==============================] - 566s 944ms/step - loss: 8.7570 - yolo_layer_1_loss: 2.3562 - yolo_layer_2_loss: 1.9701 - yolo_layer_3_loss: 4.4306 - val_loss: 11.0014 - val_yolo_layer_1_loss: 3.0256 - val_yolo_layer_2_loss: 2.5339 - val_yolo_layer_3_loss: 5.4418\n","Epoch 4/10\n","600/600 [==============================] - 563s 939ms/step - loss: 8.7272 - yolo_layer_1_loss: 2.4038 - yolo_layer_2_loss: 2.1441 - yolo_layer_3_loss: 4.1793 - val_loss: 11.3437 - val_yolo_layer_1_loss: 3.0263 - val_yolo_layer_2_loss: 2.2613 - val_yolo_layer_3_loss: 6.0562\n","Epoch 5/10\n","600/600 [==============================] - 554s 923ms/step - loss: 8.5815 - yolo_layer_1_loss: 2.2481 - yolo_layer_2_loss: 2.0361 - yolo_layer_3_loss: 4.2974 - val_loss: 10.6892 - val_yolo_layer_1_loss: 2.8837 - val_yolo_layer_2_loss: 2.5064 - val_yolo_layer_3_loss: 5.2990\n","Epoch 6/10\n","600/600 [==============================] - 546s 910ms/step - loss: 8.4106 - yolo_layer_1_loss: 2.2234 - yolo_layer_2_loss: 1.8717 - yolo_layer_3_loss: 4.3156 - val_loss: 11.1334 - val_yolo_layer_1_loss: 2.6212 - val_yolo_layer_2_loss: 2.4454 - val_yolo_layer_3_loss: 6.0668\n","Epoch 7/10\n","600/600 [==============================] - 547s 912ms/step - loss: 8.3341 - yolo_layer_1_loss: 2.2340 - yolo_layer_2_loss: 2.0466 - yolo_layer_3_loss: 4.0535 - val_loss: 10.9789 - val_yolo_layer_1_loss: 2.6318 - val_yolo_layer_2_loss: 2.3284 - val_yolo_layer_3_loss: 6.0187\n","Epoch 8/10\n","600/600 [==============================] - 548s 913ms/step - loss: 8.2668 - yolo_layer_1_loss: 2.1502 - yolo_layer_2_loss: 1.8867 - yolo_layer_3_loss: 4.2299 - val_loss: 11.1983 - val_yolo_layer_1_loss: 2.8303 - val_yolo_layer_2_loss: 2.7364 - val_yolo_layer_3_loss: 5.6316\n","Epoch 9/10\n","600/600 [==============================] - 552s 919ms/step - loss: 8.2376 - yolo_layer_1_loss: 2.1541 - yolo_layer_2_loss: 2.0053 - yolo_layer_3_loss: 4.0783 - val_loss: 10.3122 - val_yolo_layer_1_loss: 2.9411 - val_yolo_layer_2_loss: 2.2411 - val_yolo_layer_3_loss: 5.1300\n","Epoch 10/10\n","600/600 [==============================] - 548s 913ms/step - loss: 7.9100 - yolo_layer_1_loss: 2.1332 - yolo_layer_2_loss: 1.8562 - yolo_layer_3_loss: 3.9206 - val_loss: 11.9287 - val_yolo_layer_1_loss: 2.9951 - val_yolo_layer_2_loss: 2.8351 - val_yolo_layer_3_loss: 6.0985\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4CbMdHIEG4bi","colab_type":"code","outputId":"673a6ac8-80e3-447b-9844-a782c3cb09fa","executionInfo":{"status":"ok","timestamp":1575734863437,"user_tz":-60,"elapsed":689078,"user":{"displayName":"sreeni vasa hv","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGRGILT9ymLBiio6LAzf9v1Yur0IFEmPAOx9tG-0I=s64","userId":"10395202719377635148"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["metrics = trainer.evaluateModel(model_path=\"/content/Pascal_voc/models\", json_path=\"/content/Pascal_voc/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n","print(metrics)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting Model evaluation....\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","  warnings.warn('No training configuration found in save file: '\n"],"name":"stderr"},{"output_type":"stream","text":["Model File:  /content/Pascal_voc/models/detection_model-ex-001--loss-0010.629.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9163\n","Peanut: 0.9253\n","Walnut: 0.9599\n","mAP: 0.9338\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-002--loss-0009.019.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9199\n","Peanut: 0.9313\n","Walnut: 0.9710\n","mAP: 0.9408\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-003--loss-0008.757.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9035\n","Peanut: 0.9295\n","Walnut: 0.9744\n","mAP: 0.9358\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-004--loss-0008.727.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9318\n","Peanut: 0.9392\n","Walnut: 0.9576\n","mAP: 0.9429\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-005--loss-0008.581.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9234\n","Peanut: 0.9276\n","Walnut: 0.9668\n","mAP: 0.9393\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-006--loss-0008.411.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9387\n","Peanut: 0.9431\n","Walnut: 0.9613\n","mAP: 0.9477\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-007--loss-0008.334.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9105\n","Peanut: 0.9317\n","Walnut: 0.9575\n","mAP: 0.9332\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-008--loss-0008.267.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9286\n","Peanut: 0.9476\n","Walnut: 0.9376\n","mAP: 0.9379\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-009--loss-0008.238.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9253\n","Peanut: 0.9517\n","Walnut: 0.9418\n","mAP: 0.9396\n","===============================\n","Model File:  /content/Pascal_voc/models/detection_model-ex-010--loss-0007.910.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","Haselnut: 0.9111\n","Peanut: 0.9403\n","Walnut: 0.9551\n","mAP: 0.9355\n","===============================\n","[{'model_file': '/content/Pascal_voc/models/detection_model-ex-001--loss-0010.629.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9163372106040493, 'Peanut': 0.9253227969447188, 'Walnut': 0.9598822875228544}, 'map': 0.9338474316905407}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-002--loss-0009.019.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.919942144833558, 'Peanut': 0.9313457115671293, 'Walnut': 0.9710395056240275}, 'map': 0.9407757873415715}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-003--loss-0008.757.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.903486411750458, 'Peanut': 0.9294724912655751, 'Walnut': 0.9744457218026663}, 'map': 0.9358015416062332}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-004--loss-0008.727.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9317845520908885, 'Peanut': 0.9391793235621697, 'Walnut': 0.9576044885672879}, 'map': 0.942856121406782}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-005--loss-0008.581.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9233975301175317, 'Peanut': 0.9275904219893203, 'Walnut': 0.9668167561012182}, 'map': 0.9392682360693567}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-006--loss-0008.411.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9386528010894455, 'Peanut': 0.9431375785550535, 'Walnut': 0.9612751105812527}, 'map': 0.9476884967419172}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-007--loss-0008.334.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9105362656648317, 'Peanut': 0.931676617174277, 'Walnut': 0.9574524230635929}, 'map': 0.9332217686342338}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-008--loss-0008.267.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9286349558288758, 'Peanut': 0.9476081340065734, 'Walnut': 0.9375902365672054}, 'map': 0.9379444421342181}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-009--loss-0008.238.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9253181366254359, 'Peanut': 0.9517460090389196, 'Walnut': 0.9418278908739727}, 'map': 0.9396306788461094}, {'model_file': '/content/Pascal_voc/models/detection_model-ex-010--loss-0007.910.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Haselnut': 0.9111115420753618, 'Peanut': 0.9402756984998488, 'Walnut': 0.9551098077351028}, 'map': 0.9354990161034378}]\n"],"name":"stdout"}]}]}